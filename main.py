from fastapi import FastAPI, Request
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse
from fastapi.staticfiles import StaticFiles
import pandas as pd
import datetime
import re
import os  # <--- [ADD] C·∫ßn thi·∫øt ƒë·ªÉ x·ª≠ l√Ω ƒë∆∞·ªùng d·∫´n model

from apscheduler.schedulers.background import BackgroundScheduler
from contextlib import asynccontextmanager

from utils.cron_job import CronJob
# [MOD] Import th√™m TCNForecastModel
from utils.model import ForecastModel, MockForcastModel, TCNForecastModel

# ---- CONFIG ----
CITY_SLUG = "ho-chi-minh-city"
BASE_URL = (
    "https://raw.githubusercontent.com/HiAmNear/iqair-crawling"
    "/refs/heads/main/result/{city}/aqi_{city}_{year}_{month}.csv"
)

# ---- CONFIG MODEL ----
# [ADD] C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n model
MODEL_DIR = "./models"
PATH_TCN_24H = os.path.join(MODEL_DIR, "tcn_GLOBAL_task_24h_global.h5")
PATH_TCN_7D = os.path.join(MODEL_DIR, "tcn_GLOBAL_task_7d_global.h5")
PATH_SCALER = os.path.join(MODEL_DIR, "scaler.pkl")


# Map s·ªë th√°ng -> suffix trong t√™n file
MONTH_SLUGS = [
    "jan", "feb", "mar", "apr", "may", "jun",
    "jul", "aug", "sep", "oct", "nov", "dec"
]


def build_month_urls(city_slug: str, year: int):
    """T·∫°o list URL t·ª´ th√°ng 1 ƒë·∫øn th√°ng hi·ªán t·∫°i c·ªßa nƒÉm `year`."""
    today = datetime.date.today()
    current_month = today.month

    urls = []
    for m in range(1, current_month + 1):
        month_slug = MONTH_SLUGS[m - 1]
        url = BASE_URL.format(
            city=city_slug,
            year=year,
            month=month_slug,
        )
        urls.append(url)
    return urls


# ---- D√ôNG H√ÄM ·ªû TR√äN ƒê·ªÇ T·∫†O URL ----
YEAR = 2025

all_urls = build_month_urls(CITY_SLUG, YEAR)

# URL th√°ng hi·ªán t·∫°i (cu·ªëi danh s√°ch)
CSV_URL = all_urls[-1]

# C√°c URL l·ªãch s·ª≠ (t·ª´ Jan ƒë·∫øn tr∆∞·ªõc th√°ng hi·ªán t·∫°i)
HISTORY_CSV_URLS = all_urls

TARGET_CITY = "H·ªì Ch√≠ Minh"  # v·∫´n gi·ªØ nh∆∞ c≈©

# Bi·∫øn to√†n c·ª•c l∆∞u tr·ªØ d·ªØ li·ªáu trong RAM
global_data = {
    "current": {},
    "history": [],
    "forecast_24h": [],
    "forecast_7d": [],
    "heatmap_daily": [],
    "last_updated": None
}

cron_job = CronJob(CSV_URL, history_urls=HISTORY_CSV_URLS)

def extract_weather(icon_str):
    match = re.search(r"ic-w-\d{2}-([a-z-]+)-full", str(icon_str))
    return match.group(1) if match else "Kh√¥ng x√°c ƒë·ªãnh"

def fetch_and_process_data(scope: str = "current"):
    """
    H√†m worker ƒë·ªÉ t·∫£i v√† x·ª≠ l√Ω CSV.
    scope='history': L·∫•y to√†n b·ªô v√† g·ªôp c√°c th√°ng c≈©.
    scope='current': L·∫•y d·ªØ li·ªáu m·ªõi nh·∫•t.
    """
    try:
        # 1. L·∫•y dataset hi·ªán t·∫°i (s·∫Ω refresh m·ªói gi·ªù)
        df_current = cron_job.fetch()

        # 2. N·∫øu c·∫ßn l·ªãch s·ª≠ th√¨ g·ªôp t·∫•t c·∫£ th√°ng v√† ghi ra cache/history.csv
        history_df = None
        if scope == "history":
            history_df, history_path = cron_job.build_history_csv()
            if history_df is not None:
                print(f"[HISTORY] ƒê√£ g·ªôp v√† l∆∞u t·∫°i {history_path}")

        # 3. Ch·ªçn dataframe ngu·ªìn cho c√°c b∆∞·ªõc ti·∫øp theo
        df_source = history_df if history_df is not None else df_current

        if df_source is None or df_source.empty:
            print("[WARN] df_source r·ªóng, kh√¥ng c√≥ d·ªØ li·ªáu n√†o.")
            return

        # 4. L·ªçc d·ªØ li·ªáu TP.HCM v√† chu·∫©n ho√° timestamp
        hcm_df = df_source[df_source["city"] == TARGET_CITY].copy()

        # √âp h·∫øt sang string r·ªìi parse v·ªÅ UTC ƒë·ªÉ tr√°nh mixed tz
        hcm_df["timestamp"] = pd.to_datetime(
            hcm_df["timestamp"].astype(str),
            utc=True,
            errors="coerce",
        )
        # Chuy·ªÉn v·ªÅ gi·ªù Vi·ªát Nam r·ªìi b·ªè timezone (tz-naive, th·ªëng nh·∫•t)
        hcm_df["timestamp"] = (
            hcm_df["timestamp"]
            .dt.tz_convert("Asia/Ho_Chi_Minh")
            .dt.tz_localize(None)
        )

        hcm_df = hcm_df.dropna(subset=["timestamp"]).sort_values("timestamp")

        # 5. L·∫•y b·∫£n ghi m·ªõi nh·∫•t c√≥ aqi h·ª£p l·ªá (non-NaN)
        valid_rows = hcm_df.dropna(subset=["aqi"])
        if not valid_rows.empty:
            latest_valid = valid_rows.iloc[-1]
            latest_aqi = latest_valid["aqi"]
            latest_windspeed = latest_valid["wind_speed"]
            latest_humidity = latest_valid["humidity"]
            latest_weather = extract_weather(latest_valid["weather_icon"])
            aqi_value = int(latest_aqi)
            status = "K√©m" if aqi_value > 100 else "T·ªët"
            updated_time = latest_valid["timestamp"].strftime("%H:%M %d/%m")
        else:
            # Kh√¥ng c√≥ aqi th·∫≠t, ch·ªâ c√≥ timestamp gi·∫£
            latest_any = hcm_df.iloc[-1]
            aqi_value = None
            latest_windspeed = None
            latest_humidity = None
            latest_weather = None
            status = "Kh√¥ng c√≥ d·ªØ li·ªáu"
            updated_time = latest_any["timestamp"].strftime("%H:%M %d/%m")

        global_data["current"] = {
            "location": f"{TARGET_CITY}, Vietnam",
            "aqi": aqi_value,
            "windspeed": latest_windspeed,
            "humidity": latest_humidity,            
            "weather": latest_weather,
            "status": status,
            "updated": updated_time,
        }

        # 6. L∆∞u l·ªãch s·ª≠ (s·ª≠ d·ª•ng full history n·∫øu c√≥, n·∫øu kh√¥ng d√πng hi·ªán t·∫°i)
        if scope == "history":
            global_data["history"] = hcm_df.to_dict("records")
            # Trung b√¨nh theo ng√†y ƒë·ªÉ v·∫Ω heatmap, ch·ªâ d√πng aqi th·∫≠t
            daily = (
                valid_rows.assign(date=valid_rows["timestamp"].dt.date)
                .groupby("date")["aqi"]
                .mean()
                .dropna()
                .reset_index()
                .rename(columns={"aqi": "avg_aqi"})
                .sort_values("date")
            )
            global_data["heatmap_daily"] = daily.to_dict("records")

        # 7. Forecasts: d√πng d·ªØ li·ªáu ƒë√£ l√†m s·∫°ch (ch·ªâ non-NaN)
        # [MOD] S·ª≠a logic ch·ªçn model: TCN -> Baseline -> Mock
        model = None
        clean_df = valid_rows

        if clean_df.empty:
            print("[FORECAST] Kh√¥ng c√≥ d·ªØ li·ªáu s·∫°ch, d√πng Mock.")
            model = MockForcastModel()
        else:
            # ∆Øu ti√™n 1: TCN (Deep Learning)
            try:
                # Ki·ªÉm tra xem model TCN ƒë√£ load ch∆∞a (qua bi·∫øn class level)
                # TCNForecastModel s·∫Ω t·ª± check trong __init__, n·∫øu ch∆∞a load artifacts s·∫Ω raise error
                model = TCNForecastModel(clean_df)
                print("[FORECAST] ƒêang s·ª≠ d·ª•ng model TCN (Deep Learning)")
            except Exception as e_tcn:
                print(f"[FORECAST] Kh√¥ng th·ªÉ d√πng TCN ({e_tcn}). Chuy·ªÉn sang Baseline.")
                
                # ∆Øu ti√™n 2: ForecastModel (Baseline Linear Trend)
                try:
                    model = ForecastModel(clean_df)
                    print("[FORECAST] ƒêang s·ª≠ d·ª•ng ForecastModel (Baseline)")
                except Exception as e_base:
                    print(f"[FORECAST] L·ªói Baseline ({e_base}). Chuy·ªÉn sang Mock.")
                    model = MockForcastModel()

        # Th·ª±c hi·ªán d·ª± b√°o v·ªõi model ƒë√£ ch·ªçn
        try:
            global_data["forecast_24h"] = model.do_forecast_aqi_24h()
        except Exception as e:
            print(f"[FORECAST] L·ªói khi d·ª± b√°o 24h: {e}")
            global_data["forecast_24h"] = []

        try:
            global_data["forecast_7d"] = model.do_forecast_aqi_7day()
        except Exception as e:
            print(f"[FORECAST] L·ªói khi d·ª± b√°o 7 ng√†y: {e}")
            global_data["forecast_7d"] = []

        global_data["last_updated"] = datetime.datetime.now()
        print(f"[{scope.upper()}] ƒê√£ c·∫≠p nh·∫≠t d·ªØ li·ªáu l√∫c {global_data['last_updated']}")

    except Exception as e:
        print(f"L·ªói khi fetch data: {e}")


# --- SCHEDULER SETUP ---
scheduler = BackgroundScheduler()


@asynccontextmanager
async def lifespan(app: FastAPI):
    # [ADD] 0. Load Model Deep Learning v√†o RAM 1 l·∫ßn duy nh·∫•t khi kh·ªüi ƒë·ªông
    # Ki·ªÉm tra file t·ªìn t·∫°i tr∆∞·ªõc khi load ƒë·ªÉ tr√°nh crash app n·∫øu ch∆∞a copy file
    if os.path.exists(PATH_TCN_24H) and os.path.exists(PATH_TCN_7D) and os.path.exists(PATH_SCALER):
        try:
            print("üì• ƒêang load TCN Model & Scaler...")
            TCNForecastModel.load_artifacts(PATH_TCN_24H, PATH_TCN_7D, PATH_SCALER)
            print("‚úÖ Load model th√†nh c√¥ng.")
        except Exception as e:
            print(f"‚ùå L·ªói khi load model: {e}. App s·∫Ω ch·∫°y b·∫±ng model Baseline/Mock.")
    else:
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file model trong th∆∞ m·ª•c ./models. App s·∫Ω ch·∫°y b·∫±ng model Baseline.")

    # 1. Ch·∫°y ngay khi app kh·ªüi ƒë·ªông (L·∫•y l·ªãch s·ª≠ + hi·ªán t·∫°i)
    fetch_and_process_data(scope="history")

    # 2. Th√™m job: Ch·∫°y m·ªói ti·∫øng m·ªôt l·∫ßn (interval)
    scheduler.add_job(
        fetch_and_process_data,
        "interval",
        hours=1,
        args=["current"],
        id="hourly_update",
    )

    scheduler.start()
    yield
    scheduler.shutdown()


app = FastAPI(lifespan=lifespan)
templates = Jinja2Templates(directory="templates")

# --- ROUTES ---
@app.get("/", response_class=HTMLResponse)
async def read_root(request: Request):
    return templates.TemplateResponse("index.html", {"request": request})


@app.get("/api/air-quality")
async def get_air_quality():
    # Tr·∫£ v·ªÅ d·ªØ li·ªáu th·ª±c t·∫ø t·ª´ bi·∫øn to√†n c·ª•c thay v√¨ hardcode
    if not global_data["current"]:
        return {"status": "loading", "message": "ƒêang t·∫£i d·ªØ li·ªáu..."}

    repsonse = {
        "current": global_data["current"],
        "forecast_24h": global_data["forecast_24h"],
        "forecast_7d": global_data["forecast_7d"],
        "heatmap_daily": global_data["heatmap_daily"],
        "last_updated": global_data["last_updated"],
    }
    # print(repsonse) # Comment b·ªõt log cho ƒë·ª° r√°c console
    return repsonse